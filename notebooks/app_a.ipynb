{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "\n",
    "# Detectron colors\n",
    "_COLORS = np.array([\n",
    "    0.000, 0.447, 0.741,\n",
    "    0.850, 0.325, 0.098,\n",
    "    0.929, 0.694, 0.125,\n",
    "    0.494, 0.184, 0.556,\n",
    "    0.466, 0.674, 0.188\n",
    "]).astype(np.float32).reshape((-1, 3))\n",
    "\n",
    "# Random number generator seed\n",
    "_RNG_SEED = 1\n",
    "\n",
    "# Fix RNG seeds\n",
    "random.seed(_RNG_SEED)\n",
    "np.random.seed(_RNG_SEED)\n",
    "\n",
    "# Directory where sweep summaries are stored\n",
    "_DATA_DIR = '../data'\n",
    "\n",
    "# Job summary entries to append (different across re-runs; e.g. job id)\n",
    "_KEYS_TO_APPEND = ['job_id', 'rng_seed']\n",
    "\n",
    "# Job summary entries to copy (same across re-runs; e.g. flops)\n",
    "_KEYS_TO_CP = ['exp_mem', 'params', 'flops', 'net', 'optim']\n",
    "\n",
    "# Job summary entries to average (likely different across re-runs; e.g. error)\n",
    "_KEYS_TO_AVG = [\n",
    "    'act_mem', 'prec_time', 'iter_time', 'min_test_top1',\n",
    "    'train_ep_loss', 'train_ep_top1', 'test_ep_top1', 'train_it_loss', 'train_it_top1'\n",
    "]\n",
    "\n",
    "# Max flops constraint\n",
    "_MAX_F = 0.129\n",
    "# Max params constraint\n",
    "_MAX_P = 0.856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sweep(sweep_name):\n",
    "    \"\"\"Loads a sweep summary.\"\"\"\n",
    "    summary_path = os.path.join(_DATA_DIR, '{}.json'.format(sweep_name))\n",
    "    with open(summary_path, 'r') as f:\n",
    "        sweep_summary = json.load(f)\n",
    "    return sweep_summary\n",
    "\n",
    "\n",
    "def avg(vals, decs=3):\n",
    "    \"\"\"Computes the average of a list of values.\"\"\"\n",
    "    if isinstance(vals[0], (int, float)):\n",
    "        return round(np.mean(vals).item(), decs)\n",
    "    if isinstance(vals[0], list):\n",
    "        return np.around(np.mean(np.array(vals), axis=0), decs).tolist()\n",
    "    if isinstance(vals[0], dict):\n",
    "        return {k: avg([v[k] for v in vals]) for k in vals[0].keys()}\n",
    "    raise NotImplementedError(type(vals[0]))\n",
    "\n",
    "\n",
    "def combine_jobs(jobs):\n",
    "    \"\"\"Combines job summaries from different re-runs of the same job.\"\"\"\n",
    "    comb_job = {}\n",
    "    # Append values that are different across re-runs (e.g. job id)\n",
    "    for key in _KEYS_TO_APPEND:\n",
    "        comb_job['{}s'.format(key)] = [job[key] for job in jobs]\n",
    "    # Copy values that are shared across re-runs (e.g. flops)\n",
    "    for key in _KEYS_TO_CP:\n",
    "        comb_job[key] = copy.deepcopy(jobs[0][key])\n",
    "    # Average values that are likely different across re-runs (e.g. error)\n",
    "    for key in _KEYS_TO_AVG:\n",
    "        comb_job[key] = avg([job[key] for job in jobs])\n",
    "    return comb_job\n",
    "\n",
    "\n",
    "def hash_job(job, w_bt=True):\n",
    "    \"\"\"Computes a hash for a job.\"\"\"\n",
    "    return json.dumps(\n",
    "        {k: v for (k, v) in job['net'].items() if w_bt or k != 'block_type'},\n",
    "        sort_keys=True\n",
    "    )\n",
    "\n",
    "\n",
    "def combine_sweeps(sweep_summaries):\n",
    "    \"\"\"Combines sweep summaries from multiple re-runs of the same sweep.\"\"\"\n",
    "    # Group job summaries by hash\n",
    "    hash_to_js = {}\n",
    "    for ss in sweep_summaries:\n",
    "        for js in ss:\n",
    "            js_hash = hash_job(js)\n",
    "            if js_hash not in hash_to_js:\n",
    "                hash_to_js[js_hash] = [js]\n",
    "            else:\n",
    "                hash_to_js[js_hash].append(js)\n",
    "    # Combine job summaries by hash\n",
    "    return [\n",
    "        combine_jobs(job_summaries) for job_summaries in hash_to_js.values()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr wd sweeps\n",
    "sweeps_lr_wd = {\n",
    "    'Vanilla': load_sweep('Vanilla_lr-wd'),\n",
    "    'ResNet': load_sweep('ResNet_lr-wd'),\n",
    "    'DARTS': load_sweep('DARTS_lr-wd')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model rerun sweeps\n",
    "sweeps_reruns = {\n",
    "    'Vanilla': load_sweep('Vanilla_reruns'),\n",
    "    'ResNet': load_sweep('ResNet_reruns')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNG seed sweeps\n",
    "sweeps_rng = {}\n",
    "for ds in ['Vanilla', 'ResNet']:\n",
    "    sweeps_rng[ds] = {}\n",
    "    for rng in [1, 2, 3]:\n",
    "        sweep_name = '{}_rng{}'.format(ds, rng)\n",
    "        sweeps_rng[ds][rng] = load_sweep(sweep_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average across seeds\n",
    "sweeps_avg = {}\n",
    "for ds in ['Vanilla', 'ResNet']:\n",
    "    sweeps_avg[ds] = {}\n",
    "    for num_runs in [1, 2, 3]:\n",
    "        sweeps_avg[ds][num_runs] = combine_sweeps([\n",
    "            sweeps_rng[ds][rng] for rng in range(1, num_runs + 1)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Figure 12\\n')\n",
    "\n",
    "r, c = 1, 3\n",
    "w, h = 4, 3\n",
    "fig, axes = plt.subplots(nrows=r, ncols=c, figsize=(c * w, r * h))\n",
    "\n",
    "hps = ['base_lr', 'wd']\n",
    "lbs = ['learning rate (log10)', 'weight decay (log10)']\n",
    "dss = ['Vanilla', 'ResNet', 'DARTS']\n",
    "\n",
    "def_pt = [0.1, 5e-4]\n",
    "def_pt_log = np.log10(def_pt)\n",
    "\n",
    "for j, ds in enumerate(dss):\n",
    "    ax = axes[j] if r == 1 else axes[i, j]\n",
    "    sweep = sweeps_lr_wd[ds]\n",
    "    xs = [job['optim'][hps[0]] for job in sweep]\n",
    "    ys = [job['optim'][hps[1]] for job in sweep]\n",
    "    # Use log10 scale\n",
    "    xs_log = np.log10(xs)\n",
    "    ys_log = np.log10(ys)\n",
    "    # Compute relative ranks\n",
    "    errs = [job['min_test_top1'] for job in sweep]\n",
    "    ranks = np.argsort(np.argsort(errs))\n",
    "    ranks += 1\n",
    "    ranks_rel = ranks / (len(ranks))\n",
    "    # Plot relative ranks\n",
    "    s = ax.scatter(xs_log, ys_log, c=ranks_rel, alpha=0.1, cmap='viridis', rasterized=True)\n",
    "    ax.set_xlabel('{}'.format(lbs[0]), fontsize=16)\n",
    "    if j == 0:\n",
    "        ax.set_ylabel('{}'.format(lbs[1]), fontsize=16)\n",
    "    xlim_log = np.log10([0.001, 1.0])\n",
    "    ylim_log = np.log10([0.00001, 0.01])\n",
    "    ax.set_xlim(xlim_log)\n",
    "    ax.set_ylim(ylim_log)\n",
    "    ax.grid(alpha=0.4)\n",
    "    # Show default setting\n",
    "    def_pt_alpha = 0.8\n",
    "    pr_col = _COLORS[1]\n",
    "    ax.scatter(def_pt_log[0], def_pt_log[1], color=pr_col, alpha=def_pt_alpha)\n",
    "    ax.plot(\n",
    "        np.linspace(xlim_log[0], def_pt_log[0], 10), [def_pt_log[1] for _ in range(10)],\n",
    "        color=pr_col, alpha=def_pt_alpha, linestyle='--', linewidth=2.5\n",
    "    )\n",
    "    ax.plot(\n",
    "        [def_pt_log[0] for _ in range(10)], np.linspace(ylim_log[0], def_pt_log[1], 10),\n",
    "        color=pr_col, alpha=def_pt_alpha, linestyle='--', linewidth=2.5\n",
    "    )\n",
    "    ax.set_title(ds, fontsize=16)\n",
    "\n",
    "fig.colorbar(s, ax=axes.ravel().tolist());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Figure 13\\n')\n",
    "\n",
    "r, c = 1, 2\n",
    "w, h = 4, 3\n",
    "fig, axes = plt.subplots(nrows=r, ncols=c, figsize=(c * w, r * h))\n",
    "\n",
    "dss = ['Vanilla', 'ResNet']\n",
    "cs = ['top', 'mid']\n",
    "cs_ls = ['top-ranked', 'mid-ranked']\n",
    "bin_size = 0.1\n",
    "\n",
    "for i, ds in enumerate(dss):\n",
    "    ax = axes[i]\n",
    "    for j, c in enumerate(cs):\n",
    "        sweep = sweeps_reruns[ds][c]\n",
    "        errs = [job['min_test_top1'] for job in sweep]\n",
    "        num_bins = int((max(errs) - min(errs)) / bin_size)\n",
    "        ax.hist(\n",
    "            errs, bins=num_bins, color=_COLORS[j], alpha=0.8,\n",
    "            label='{}'.format(cs_ls[j])\n",
    "        )\n",
    "    if ds == 'Vanilla':\n",
    "        ax.set_xlim([4.5, 10])\n",
    "    else:\n",
    "        ax.set_xlim([4.5, 10])\n",
    "    ax.grid(alpha=0.4)\n",
    "    ax.set_ylim([0, 40])\n",
    "    ax.legend(loc='upper right', prop={'size': 13}, ncol=1)\n",
    "    ax.set_xlabel('error', fontsize=16)\n",
    "    ax.set_ylabel('number of runs', fontsize=16)\n",
    "    ax.set_title(ds, fontsize=16)\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Figure 14\\n')\n",
    "\n",
    "# Plot EDFs for varying number of reruns\n",
    "r, c = 1, 2\n",
    "w, h = 4, 3\n",
    "fig, axes = plt.subplots(nrows=r, ncols=c, figsize=(c * w, r * h))\n",
    "dss = ['Vanilla', 'ResNet']\n",
    "\n",
    "for i, ds in enumerate(dss):\n",
    "    ax = axes[i]\n",
    "    for j in [1, 2, 3]:\n",
    "        sweep = [job for job in sweeps_avg[ds][j]]\n",
    "        errs = sorted([job['min_test_top1'] for job in sweep])\n",
    "        ax.plot(\n",
    "            errs, np.linspace(0, 1, len(errs)),\n",
    "            color=_COLORS[j], linewidth=2, alpha=0.8, label='{} reruns'.format(j)\n",
    "        )\n",
    "    ax.grid(alpha=0.4)\n",
    "    ax.set_xlabel('error', fontsize=16)\n",
    "    ax.set_ylabel('cumulative prob.', fontsize=16)\n",
    "    ax.set_xlim([4.5, 17.5])\n",
    "    ax.set_xticks([5.0, 7.5, 10.0, 12.5, 15.0, 17.5])\n",
    "    ax.set_title(ds, fontsize=16)\n",
    "    ax.legend(loc='lower right', prop={'size': 13})\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anp_cloned_from": {
   "notebook_id": "332248340824174",
   "revision_id": "2425268394363873"
  },
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
